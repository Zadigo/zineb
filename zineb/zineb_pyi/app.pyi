from typing import Any, List, Type, TypeVar, Union

from zineb.http.request import HTTPRequest
from zineb.http.responses import HTMLResponse, JsonResponse, XMLResponse
from zineb.utils.iteration import RequestQueue
from zineb.utils.iteration import collect_files
from bs4 import BeautifulSoup

# T = TypeVar('T', bound='Spider')

class SpiderOptions:
    base_url: str = ...
    domains: list = ...
    limit_requests_to: int = ...
    python_path: str = ...
    prepared_requests: RequestQueue = ...
    spider: Type = ...
    spider_name: str = ...
    start_urls: list = ...
    verbose_name: str = ...
    def __init__(self) -> None: ...
    def __repr__(self) -> str: ...
    def __getitem__(self, name) -> str: ...
    def initialize_queue(self) -> None: ...
    def update_options(self, cls: Type, name: str) -> None: ...
    def add(self, name: str, value: Any) -> None: ...
    

class BaseSpider(type):
    def __new__(cls, name: str, bases: tuple, attrs: dict): ...


class Spider(metaclass=BaseSpider):
    meta: SpiderOptions = ...
    start_urls: List[str] = ...
    def __init__(self): ...
    def __repr__(self) -> str: ...
    def __getattribute__(self, name! str) -> Any: ...
    def _resolve_requests(self) -> None: ...
    def start(self, response: Union[HTMLResponse, JsonResponse, XMLResponse], request: HTTPRequest = None, **kwargs) -> Any: ...


# class SitemapCrawler(Spider): ...


class FileCrawler:
    start_files: Union[List[str], collect_files] = ...
    root_dir: str = ...
    def __init__(self) -> None: ...
    def __del__(self) -> None: ...
    def start(self, soup: BeautifulSoup, **kwargs) -> None: ...
