import csv
import json
import pathlib
from functools import lru_cache
from io import BytesIO
from typing import Any, List, Optional, Type, TypeVar, Union
# from zineb.storages import FileDescriptor
from PIL.Image import Image

# _FileDescriptor = TypeVar('_FileDescriptor', FileDescriptor, contravariant=True)

class FileDescriptor:
    buffer: Type[BytesIO] = ...
    def __init__(self) -> None: ...
    def __get__(self, instance: File, cls: Optional[None] = ...) -> BytesIO: ...
    def open_file(self, instance: File) -> None: ...


class File:
    content: FileDescriptor = ...
    extension: str = ...
    full_path: str = ...
    is_valid: bool = ...
    name: str = ...
    size: int = ...
    verbose_name: str = ...
    def __init__(self, full_path: str) -> None: ...
    def __repr__(self) -> str: ...
    def __eq__(self, value: Any) -> bool: ...
    def __hash__(self) -> int: ...
    def __enter__(self, *args, **kwargs) -> File: ...
    def __exit__(self, *args, **kwargs) -> bool: ...
    @classmethod
    def create(cls, full_path: str) -> File: ...
    def choose_parser(self, extension: str) -> Union[json.load, csv.reader, Image]: ...


class BaseStorage:
    storage: None = ...
    def __init__(self) -> None: ...
    def prepare(self) -> None: ...
    def save(self, name, content: Any = ...): ...
    def open_file(self, name: str) -> Any: ...
    def filename_generator(self, old_name: str) -> str: ...
    def path(self) -> str: ...
    def delete(self) -> None: ...
    def exists(self) -> bool: ...
    def size(self) -> int: ...
        

class FileSystemStorage(BaseStorage):
    files = []
    storage_path: Union[str, pathlib.Path] = ...
    storage: List = ...
    def __init__(self) -> None: ...
    @lru_cache(maxsize=10)
    def load_files(self) -> List: ...
    def prepare(self) -> None: ...
    def get_file(self, name: str) -> File: ...


class AWSFileSystemStorage(BaseStorage): ...
